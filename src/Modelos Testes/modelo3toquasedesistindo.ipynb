{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nTo use the 'notebook' renderer, you must install the vega package\nand the associated Jupyter extension.\nSee https://altair-viz.github.io/getting_started/installation.html\nfor more information.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/altair/utils/plugin_registry.py:151\u001b[0m, in \u001b[0;36mPluginRegistry._enable\u001b[0;34m(self, name, **options)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     (ep,) \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    152\u001b[0m         ep\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m importlib_metadata_get(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentry_point_group)\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m ep\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m name\n\u001b[1;32m    155\u001b[0m     ]\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 1, got 0)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01maltair\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01malt\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Enable the Altair renderer for Jupyter Notebook (or your environment)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43malt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnotebook\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Ler os arquivos CSV em Dataframes Pandas\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/altair/utils/plugin_registry.py:190\u001b[0m, in \u001b[0;36mPluginRegistry.enable\u001b[0;34m(self, name, **options)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactive\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPluginEnabler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/altair/utils/plugin_registry.py:37\u001b[0m, in \u001b[0;36mPluginEnabler.__init__\u001b[0;34m(self, registry, name, **options)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions \u001b[38;5;241m=\u001b[39m options  \u001b[38;5;66;03m# type: Dict[str, Any]\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_state \u001b[38;5;241m=\u001b[39m registry\u001b[38;5;241m.\u001b[39m_get_state()  \u001b[38;5;66;03m# type: Dict[str, Any]\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_enable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/altair/utils/plugin_registry.py:158\u001b[0m, in \u001b[0;36mPluginRegistry._enable\u001b[0;34m(self, name, **options)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentrypoint_err_messages:\n\u001b[0;32m--> 158\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentrypoint_err_messages[name]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NoSuchEntryPoint(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentry_point_group, name) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: \nTo use the 'notebook' renderer, you must install the vega package\nand the associated Jupyter extension.\nSee https://altair-viz.github.io/getting_started/installation.html\nfor more information.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import altair as alt\n",
    "\n",
    "# Enable the Altair renderer for Jupyter Notebook (or your environment)\n",
    "alt.renderers.enable('notebook')  \n",
    "\n",
    "# Ler os arquivos CSV em Dataframes Pandas\n",
    "try:\n",
    "    df_performance = pd.read_csv('/home/rhudson/Documentos/PUC/Projeto em ciência de dados I/ppl-cd-pcd-sist-int-2024-1-sleepresearch-2024-1/assets/data/Student_Performance.csv', on_bad_lines='warn')\n",
    "    df_stress = pd.read_csv('/home/rhudson/Documentos/PUC/Projeto em ciência de dados I/ppl-cd-pcd-sist-int-2024-1-sleepresearch-2024-1/assets/data/Student Stress Factors.csv', on_bad_lines='warn')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading CSV files: {e}\")\n",
    "    exit(1)  # Exit if files are not found\n",
    "\n",
    "# Criar uma nova coluna `ID do Estudante` no `df_performance`, atribuindo um ID único inteiro para cada estudante (de 1 a 10000).\n",
    "df_performance['ID do Estudante'] = range(1, len(df_performance) + 1)\n",
    "\n",
    "# Randomiza 520 linhas do `df_performance` e armazená-las em `df_performance_sample`.\n",
    "df_performance_sample = df_performance.sample(n=520, random_state=1)\n",
    "\n",
    "# Combinar `df_performance_sample` com `df_stress` com base no índice.\n",
    "try:\n",
    "    df_combined = pd.merge(df_performance_sample, df_stress, left_index=True, right_index=True)\n",
    "except KeyError as e:\n",
    "    print(f\"Error merging DataFrames: {e}\")\n",
    "    exit(1)  # Exit if there's a merge error\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = df_combined.select_dtypes(include='object').columns\n",
    "\n",
    "try:\n",
    "    # One-Hot Encoding\n",
    "    ohe = OneHotEncoder(drop='first')\n",
    "    df_combined_encoded = pd.DataFrame(ohe.fit_transform(df_combined[categorical_cols]), columns=ohe.get_feature_names_out(categorical_cols))\n",
    "    df_combined = pd.concat([df_combined.drop(categorical_cols, axis=1), df_combined_encoded], axis=1)\n",
    "except ValueError as e:\n",
    "    print(f\"Error during OneHotEncoding: {e}\")\n",
    "    print(df_combined[categorical_cols].head())\n",
    "    exit(1)  # Exit if there's an error during encoding\n",
    "\n",
    "# Separar os recursos (X) e a variável alvo (y) do `df_combined`.\n",
    "X = df_combined.drop('Performance Index', axis=1)\n",
    "y = df_combined['Performance Index']\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "# Normalizar os recursos usando MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Construir, compilar e treinar o modelo de rede neural\n",
    "model = Sequential()\n",
    "model.add(Dense(X.shape[1], input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_split=0.2)\n",
    "\n",
    "# Prever no conjunto de teste e calcular métricas\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Mean Absolute Error on Test Set: {mae:.2f}')\n",
    "print(f'R-squared on Test Set: {r2:.2f}')\n",
    "\n",
    "\n",
    "# Criar o gráfico de dispersão de valores reais vs. preditos\n",
    "df_plot = pd.DataFrame({'Real Values': y_test, 'Predicted Values': y_pred.flatten()})\n",
    "scatter_plot = alt.Chart(df_plot).mark_circle(size=60).encode(\n",
    "    x=alt.X('Real Values', title='Valores Reais'),\n",
    "    y=alt.Y('Predicted Values', title='Valores Preditos'),\n",
    "    tooltip=['Real Values', 'Predicted Values']\n",
    ").properties(\n",
    "    title='Valores Reais vs. Valores Preditos'\n",
    ").interactive()\n",
    "\n",
    "# Adicionar a linha x=y ao gráfico\n",
    "line = alt.Chart(pd.DataFrame({'x': [y.min(), y.max()], 'y': [y.min(), y.max()]})).mark_line().encode(\n",
    "    x='x', y='y', color=alt.value('red')\n",
    ")\n",
    "\n",
    "# Combinar o gráfico de dispersão e a linha\n",
    "chart = scatter_plot + line\n",
    "\n",
    "# Display the chart\n",
    "chart\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
